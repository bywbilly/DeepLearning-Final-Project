args = {
    'num_wavepoint': 100,
    'mfcc': 6,
    'rate': 70,
    'num_mfcc': 1000,
    'num_slope': 0,
    'lr_decay': 1.0,
    'dropout': 0.5,
    'hidden_dim': [128, 80, 4],
    'num_epoch': 200,
    'batch_size': 4,
    'optimizer': 'adam',
    'init_lr': 0.001,
    'use_L2': True,
    'use_L1': False,
    'L2_reg': 0.0005,
    'L1_reg': 0.0005,
}

layers.append(tfnnutils.InputLayer())
layers.append(tfnnutils.Conv2D('conv1', ksize=(1, 10), kernels=96))
layers.append(tfnnutils.MaxPool(ksize=(1, 2)))
layers.append(tfnnutils.Conv2D('conv2', ksize=(1, 10), kernels=108))
layers.append(tfnnutils.MaxPool(ksize=(1, 2)))
layers.append(tfnnutils.Conv2D('conv3', ksize=(1, 10), kernels=108))
layers.append(tfnnutils.MaxPool(ksize=(1, 2)))
layers.append(tfnnutils.Conv2D('conv4', ksize=(1, 10), kernels=16))
layers.append(tfnnutils.Flatten())
for i in xrange(len(self.hidden_dim)):
    if i == len(self.hidden_dim) - 1:
        layers.append(tfnnutils.FCLayer('FC%d'%(i+1), dims[i], act=None))
    else:
        layers.append(tfnnutils.FCLayer('FC%d'%(i+1), dims[i], act=tf.nn.relu))
    if i == 0 and self.args['dropout'] < 1:
        layers.append(tfnnutils.Dropout())